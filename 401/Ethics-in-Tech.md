# Ethics in Tech

## Google and AI

I personally do agree with this approach at using AI for security purposes. As a former military member myself, I know there are possible threats out there and it is better to stay ahead of them. I think that Google has found a strong middle ground for what to do when it comes to using AI in military matters. Non offensive operations should be able to be used to produce better results and success rate especially when it comes to save people's lives like search and rescue missions. This was an interesting read and got me thinking about the affects tech can have if not controlled correctly.

## Ethical dilemma of self driving cars

The deployment of self-driving technology has generated a debate over how to address ethical dilemmas that might arise when autonomous vehicles encounter situations that they cannot predict. A central ethical question is, if an autonomous vehicle has no other choice but to cause an accident, who should it harm? This is a tough question and I believe the answer changes depending on where you are in relation to the accident. If you are the person in the car, you would want the car to protect you in most cases, but if you are in harms way of the car you would want it to avoid hitting you at all costs. This creates an impossible dilemma where you can never predict all the possible situations. Does that mean we should scratch the whole project? Personally, I am willing to take the risk of self-driving vehicles, but I know there are people who would not share my same opinion and that is what makes these ethical questions so difficult.

### Sources

- [https://nextjs.org/learn/basics/dynamic-routes](https://gizmodo.com/in-reversal-google-says-its-ai-will-not-be-used-for-we-1826649327)
- [https://nextjs.org/learn/basics/deploying-nextjs-app](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/)

[Back To Home](../README.md)
