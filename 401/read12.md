# Linear Regressions

## How to Run Linear Regression in Python

- **Linear regression** can be thought of as finding the straight line that best fits a set of scattered data points
- You can then project that line to predict new data points. Linear regression is a fundamental ML algorithm due to its comparatively simple and core properties.
- A basic understanding of statistical math is key to comprehending linear regression, as is a good grounding in ML concepts.
- A scikit-learn linear regression script begins by importing the LinearRegression class
- Although the class is not visible in the script, it contains default parameters that do the heavy lifting for simple least squares linear regression
- 
#### The following are some key concepts you will come across when you work with scikit-learnâ€™s linear regression method:

- **Best Fit** â€“ the straight line in a plot that minimizes the deviation between related scattered data points.
- **Coefficient** â€“ also known as a parameter, is the factor a variable is multiplied by. In linear regression, a coefficient represents changes in a Response Variable (see below).
- **Coefficient** of Determination â€“ the correlation coefficient denoted as ğ‘…Â². Used to describe the precision or degree of fit in a regression. 
- **Correlation** â€“ the relationship between two variables in terms of quantifiable strength and degree, often referred to as the â€˜degree of correlationâ€™.  Values range between -1.0 and 1.0. 
- **Dependent Feature** â€“ a variable denoted as y in the slope equation y=ax+b. Also known as an Output, or a Response. 
- **Estimated Regression Line** â€“ the straight line that best fits a set of scattered data points.
- **Independent Feature** â€“ a variable denoted as x in the slope equation y=ax+b. Also known as an Input, or a predictor. 
- **Intercept** â€“ the location where the Slope intercepts the Y-axis denoted b in the slope equation y=ax+b. 
- **Least Squares** â€“ a method of estimating a Best Fit to data, by minimizing the sum of the squares of the differences between observed and estimated values.
- **Mean** â€“ an average of a set of numbers, but in linear regression, Mean is modeled by a linear function.
- **Ordinary Least Squares Regression (OLS) â€“ more commonly known as Linear Regression. 
- **Residual** â€“ vertical distance between a data point and the line of regression (see Residual in Figure 1 below).
- **Regression** â€“ estimate of predictive change in a variable in relation to changes in other variables (see Predicted Response in Figure 1 below).
- **Regression Model** â€“ the ideal formula for approximating a regression.
- **Response Variables** â€“ includes both the Predicted Response (the value predicted by the regression) and the Actual Response, which is the actual value of the data point (see Figure 1 below).
- **Slope** â€“ the steepness of a line of regression. Slope and Intercept can be used to define the linear relationship between two variables: y=ax+b.
- **Simple** Linear Regression â€“ a linear regression that has a single independent variable.
### Sources

- <https://www.activestate.com/resources/quick-reads/how-to-run-linear-regressions-in-python-scikit-learn/>
- <https://realpython.com/linear-regression-in-python/>

[Back To Home](../README.md)